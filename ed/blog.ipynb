{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5huAQ9MU92",
        "outputId": "32d4d071-1313-4a21-8ebd-8143343940ef"
      },
      "outputs": [],
      "source": [
        "# !pip install torch==1.4.0 torchvision==0.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_JjVd5tNi6V",
        "outputId": "20e741e9-a4ff-4a32-e462-35a7f2507dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA TITAN RTX\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OQD_bSRkXBp"
      },
      "outputs": [],
      "source": [
        "!mkdir input\n",
        "!mkdir outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZFOUghojR7u",
        "outputId": "266e3bce-853a-418e-82b7-9c669d744956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing dcgan.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile dcgan.py\n",
        "import torch.nn as nn\n",
        "\n",
        "# generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz):\n",
        "        super(Generator, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.main = nn.Sequential(\n",
        "            # nz will be the input to the first convolution\n",
        "            nn.ConvTranspose2d(\n",
        "                nz, 512, kernel_size=4, \n",
        "                stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                512, 256, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                256, 128, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                128, 64, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                64, 3, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "# discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                3, 64, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(\n",
        "                64, 128, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(\n",
        "                128, 256, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(\n",
        "                256, 512, kernel_size=4, \n",
        "                stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(\n",
        "                512, 1, kernel_size=4, \n",
        "                stride=1, padding=0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-YIJHRCjmb6",
        "outputId": "5989a698-32d2-4274-a8ff-91fb0f689bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# set the computation device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def label_real(size):\n",
        "    \"\"\"\n",
        "    Fucntion to create real labels (ones)\n",
        "    :param size: batch size\n",
        "    :return real label vector\n",
        "    \"\"\"\n",
        "    data = torch.ones(size, 1)\n",
        "    return data.to(device)\n",
        "\n",
        "def label_fake(size):\n",
        "    \"\"\"\n",
        "    Fucntion to create fake labels (zeros)\n",
        "    :param size: batch size\n",
        "    :returns fake label vector\n",
        "    \"\"\"\n",
        "    data = torch.zeros(size, 1)\n",
        "    return data.to(device)\n",
        "\n",
        "def create_noise(sample_size, nz):\n",
        "    \"\"\"\n",
        "    Fucntion to create noise\n",
        "    :param sample_size: fixed sample size or batch size\n",
        "    :param nz: latent vector size\n",
        "    :returns random noise vector\n",
        "    \"\"\"\n",
        "    return torch.randn(sample_size, nz, 1, 1).to(device)\n",
        "\n",
        "def save_generator_image(image, path):\n",
        "    \"\"\"\n",
        "    Function to save torch image batches\n",
        "    :param image: image tensor batch\n",
        "    :param path: path name to save image\n",
        "    \"\"\"\n",
        "    save_image(image, path, normalize=True)\n",
        "\n",
        "def weights_init(m):\n",
        "    \"\"\"\n",
        "    This function initializes the model weights randomly from a \n",
        "    Normal distribution. This follows the specification from the DCGAN paper.\n",
        "    https://arxiv.org/pdf/1511.06434.pdf\n",
        "    Source: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK8Xmc5tjyTo",
        "outputId": "f83f5083-0501-4c37-d76a-201856717b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing train_dcgan.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile train_dcgan.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "from utils import save_generator_image, weights_init\n",
        "from utils import label_fake, label_real, create_noise\n",
        "from dcgan import Generator, Discriminator\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "# learning parameters / configurations according to paper\n",
        "image_size = 256 # we need to resize image to 64x64\n",
        "batch_size = 64\n",
        "nz = 100 # latent vector size\n",
        "beta1 = 0.5 # beta1 value for Adam optimizer\n",
        "lr = 0.0002 # learning rate according to paper\n",
        "sample_size = 64 # fixed sample size\n",
        "epochs = 25 # number of epoch to train\n",
        "\n",
        "# set the computation device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# image transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), \n",
        "    (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# prepare the data\n",
        "train_data = datasets.CIFAR10(\n",
        "    root='input/data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# initialize models\n",
        "generator = Generator(nz).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# initialize generator weights\n",
        "generator.apply(weights_init)\n",
        "# initialize discriminator weights\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "print('##### GENERATOR #####')\n",
        "print(generator)\n",
        "print('######################')\n",
        "\n",
        "print('\\n##### DISCRIMINATOR #####')\n",
        "print(discriminator)\n",
        "print('######################')\n",
        "\n",
        "# optimizers\n",
        "optim_g = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optim_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "losses_g = [] # to store generator loss after each epoch\n",
        "losses_d = [] # to store discriminator loss after each epoch\n",
        "\n",
        "# function to train the discriminator network\n",
        "def train_discriminator(optimizer, data_real, data_fake):\n",
        "    b_size = data_real.size(0)\n",
        "    # get the real label vector\n",
        "    real_label = label_real(b_size)\n",
        "    # get the fake label vector\n",
        "    fake_label = label_fake(b_size)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get the outputs by doing real data forward pass\n",
        "    output_real = discriminator(data_real).view(-1)\n",
        "    loss_real = criterion(output_real, real_label)\n",
        "\n",
        "    # get the outputs by doing fake data forward pass\n",
        "    output_fake = discriminator(data_fake)\n",
        "    loss_fake = criterion(output_fake, fake_label)\n",
        "\n",
        "    # compute gradients of real loss \n",
        "    loss_real.backward()\n",
        "    # compute gradients of fake loss\n",
        "    loss_fake.backward()\n",
        "    # update discriminator parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss_real + loss_fake\n",
        "\n",
        "# function to train the generator network\n",
        "def train_generator(optimizer, data_fake):\n",
        "    b_size = data_fake.size(0)\n",
        "    # get the real label vector\n",
        "    real_label = label_real(b_size)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # output by doing a forward pass of the fake data through discriminator\n",
        "    output = discriminator(data_fake)\n",
        "    loss = criterion(output, real_label)\n",
        "\n",
        "    # compute gradients of loss\n",
        "    loss.backward()\n",
        "    # update generator parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss    \n",
        "\n",
        "# create the noise vector\n",
        "noise = create_noise(sample_size, nz)\n",
        "# print('SIZE', noise.size())\n",
        "# print('NOISE', noise)\n",
        "\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_g = 0.0\n",
        "    loss_d = 0.0\n",
        "    for bi, data in tqdm(enumerate(train_loader), total=int(len(train_data)/train_loader.batch_size)):\n",
        "        image, _ = data\n",
        "        image = image.to(device)\n",
        "        b_size = len(image)\n",
        "        # forward pass through generator to create fake data\n",
        "        data_fake = generator(create_noise(b_size, nz)).detach()\n",
        "        data_real = image\n",
        "        loss_d += train_discriminator(optim_d, data_real, data_fake)\n",
        "        data_fake = generator(create_noise(b_size, nz))\n",
        "        loss_g += train_generator(optim_g, data_fake)\n",
        "\n",
        "    # final forward pass through generator to create fake data...\n",
        "    # ...after training for current epoch\n",
        "    generated_img = generator(noise).cpu().detach()\n",
        "    # save the generated torch tensor models to disk\n",
        "    save_generator_image(generated_img, f\"outputs/gen_img{epoch}.png\")\n",
        "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
        "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
        "    losses_g.append(epoch_loss_g)\n",
        "    losses_d.append(epoch_loss_d)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")\n",
        "\n",
        "print('DONE TRAINING')\n",
        "# save the model weights to disk\n",
        "torch.save(generator.state_dict(), 'outputs/generator.pth')\n",
        "\n",
        "# plot and save the generator and discriminator loss\n",
        "plt.figure()\n",
        "plt.plot(losses_g, label='Generator loss')\n",
        "plt.plot(losses_d, label='Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig('outputs/loss.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkfJL5ZqkQbG",
        "outputId": "f8ce5271-c35f-44e3-f639-3bfa9597368e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to input/data/cifar-10-python.tar.gz\n",
            "170500096it [00:01, 96063961.21it/s]                   \n",
            "Extracting input/data/cifar-10-python.tar.gz to input/data\n",
            "##### GENERATOR #####\n",
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "######################\n",
            "\n",
            "##### DISCRIMINATOR #####\n",
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n",
            "######################\n",
            "  0% 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "100% 390/390 [01:47<00:00,  3.55it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([80, 1])) that is different to the input size (torch.Size([80])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([80, 1])) that is different to the input size (torch.Size([80, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "391it [01:47,  3.64it/s]\n",
            "Epoch 1 of 25\n",
            "Generator loss: 12.18607140, Discriminator loss: 0.49181098\n",
            " 10% 40/390 [00:11<01:39,  3.53it/s]Traceback (most recent call last):\n",
            "  File \"train_dcgan.py\", line 138, in <module>\n",
            "    loss_d += train_discriminator(optim_d, data_real, data_fake)\n",
            "  File \"train_dcgan.py\", line 95, in train_discriminator\n",
            "    loss_fake.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 195, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            " 10% 40/390 [00:11<01:40,  3.50it/s]\n"
          ]
        }
      ],
      "source": [
        "!python train_dcgan.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-fl1cG1Tkg0l"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "from fastai.vision.learner import create_body\n",
        "from torchvision.models.resnet import resnet18, resnet50\n",
        "from fastai.vision.models.unet import DynamicUnet\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_fastai_model(in_channels=1, out_channels=2, image_shape=(256,256)):\n",
        "    model_body = create_body(resnet18(), n_in=in_channels, cut=-2)\n",
        "    model = DynamicUnet(encoder=model_body, n_out=out_channels, img_size=image_shape)\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "SIZE = 256\n",
        "model = build_fastai_model(in_channels=1, out_channels=2, image_shape=(SIZE,SIZE))\n",
        "out = build_fastai_model(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DynamicUnet(\n",
              "  (layers): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (7): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (4): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): PixelShuffle_ICNR(\n",
              "      (0): ConvLayer(\n",
              "        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "    (9): ResizeToOrig()\n",
              "    (10): MergeLayer()\n",
              "    (11): ResBlock(\n",
              "      (convpath): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(98, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv2d(98, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (idpath): Sequential()\n",
              "      (act): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): ConvLayer(\n",
              "      (0): Conv2d(98, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (13): fastai.layers.ToTensorBase(tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DynamicUnet(\n",
              "  (layers): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (7): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Sequential(\n",
              "      (0): ConvLayer(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (1): ConvLayer(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (4): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): UnetBlock(\n",
              "      (shuf): PixelShuffle_ICNR(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): PixelShuffle(upscale_factor=2)\n",
              "      )\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): ConvLayer(\n",
              "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (conv2): ConvLayer(\n",
              "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): PixelShuffle_ICNR(\n",
              "      (0): ConvLayer(\n",
              "        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): ReLU()\n",
              "      )\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "    (9): ResizeToOrig()\n",
              "    (10): MergeLayer()\n",
              "    (11): ResBlock(\n",
              "      (convpath): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (idpath): Sequential()\n",
              "      (act): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): ConvLayer(\n",
              "      (0): Conv2d(97, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (13): fastai.layers.ToTensorBase(tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('woosuk': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "19d343098935f0d21913e0ce7f8bdfecc8df0710860d9dfa1d07e023e8636bf0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
