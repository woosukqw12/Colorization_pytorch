{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as vision_models\n",
    "\n",
    "# pip install fastai==2.4\n",
    "from fastai.vision.learner import create_body\n",
    "from torchvision.models.resnet import resnet18, resnet50\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# module import \n",
    "from utils import *\n",
    "from dataset import *\n",
    "from transforms import *\n",
    "from model_Unet import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 224, 224), True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.epoch = 20\n",
    "        self.batch_size = 64\n",
    "        self.lr = 0.0001\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.size = 224\n",
    "        self.channels = 3\n",
    "        self.latent_dim = 100 # size of generator input\n",
    "        \n",
    "        \n",
    "config = Config()\n",
    "img_shape = (config.channels, config.size, config.size)\n",
    "\n",
    "device = True if torch.cuda.is_available() else False\n",
    "img_shape, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callback import *\n",
    "from fastai.vision.gan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_colab = None\n",
    "\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "home = \"./input\"\n",
    "\n",
    "\n",
    "def build_fastai_model(in_channels=1, out_channels=2, image_shape=(224, 224)):\n",
    "    model_body = create_body(resnet18(), n_in=in_channels, cut=-2)\n",
    "    model = DynamicUnet(encoder=model_body, n_out=out_channels, img_size=image_shape)\n",
    "    return model.to(device)\n",
    "\n",
    "def build_fastai_model_50(in_channels=1, out_channels=2, image_shape=(224, 224)):\n",
    "    model_body = create_body(resnet50(), n_in=in_channels, cut=-2)\n",
    "    model = DynamicUnet(encoder=model_body, n_out=out_channels, img_size=image_shape)\n",
    "    return model.to(device)    \n",
    "\n",
    "\n",
    "def pretrain_generator(net_G, train_dl, opt, criterion=nn.L1Loss(), epochs=20):\n",
    "    for e in range(epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        for x, y in tqdm(train_dl):\n",
    "            L, ab = x.to(device), y.to(device)\n",
    "            preds = net_G(L)\n",
    "            loss = criterion(preds, ab)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            loss_meter.update(loss.item(), L.size(0))\n",
    "            \n",
    "        print(f\"Epoch {e + 1}/{epochs}\")\n",
    "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config & data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [224, 224]\n",
    "batch_size = 32\n",
    "num_examples = -1\n",
    "device=  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "epochs = 100\n",
    "plot_freq = 5\n",
    "\n",
    "\n",
    "ab_train, ab_test, l_train, l_test = load_data(\"input\", channels_first=True)\n",
    "    \n",
    "input_transforms = [transform_expand_dim(axis=2),\n",
    "                    to_channel_first,\n",
    "                   transform_divide(255.0)\n",
    "                   ]\n",
    "output_transforms = [\n",
    "                    to_channel_first,\n",
    "                   transform_divide(255.0)\n",
    "                   ]\n",
    "\n",
    "ds_train = DatasetImg(l_train[:num_examples], ab_train[:num_examples], input_transforms=input_transforms, output_transforms=output_transforms)\n",
    "train_dl = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ds_test = DatasetImg(l_test[:num_examples], ab_test[:num_examples], input_transforms=input_transforms, output_transforms=output_transforms)\n",
    "test_dl = DataLoader(ds_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_G = build_fastai_model(in_channels=1, out_channels=2, image_shape=(224,224))\n",
    "opt = torch.optim.Adam(net_G.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()        \n",
    "pretrain_generator(net_G, train_dl, opt, criterion, 20)\n",
    "torch.save(net_G.state_dict(), \"pretrained_res18-unet2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('woosuk': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d343098935f0d21913e0ce7f8bdfecc8df0710860d9dfa1d07e023e8636bf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
